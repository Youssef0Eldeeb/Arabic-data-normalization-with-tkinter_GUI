{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a443458",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ذهب الطالب الي المدرسة، ولقد نجح في الامتحان. رأيت القمر بازغا\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8369914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentaion\n",
    "import pandas as pd\n",
    "import nltk\n",
    "def segmentation(txt):\n",
    "    punkt = nltk.data.load(r'./tokenizers/punkt/english.pickle')\n",
    "    tx = open(f'{txt}','a')\n",
    "    segmentedText = punkt.tokenize(tx)\n",
    "    \n",
    "#     pdcsv = pd.read_csv(f'{txt}')\n",
    "#     finalTxext = pdcsv.to_string()\n",
    "    tkinter.messagebox.showinfo(\"Segmented Text\",tx) \n",
    "# segmentation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a70696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "def tokenization(txt):\n",
    "    tokenizedText = nltk.word_tokenize(txt)\n",
    "    return tokenizedText\n",
    "# tokenization(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56fee8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword Removing\n",
    "from nltk.corpus import stopwords\n",
    "stopWordList = stopwords.words('arabic')\n",
    "def stopwordRemoving(txt):\n",
    "    SWCleanText = []\n",
    "    tokensText = tokenization(text)\n",
    "    for token in tokensText:\n",
    "        if token not in stopWordList:\n",
    "            SWCleanText.append(token)\n",
    "    return SWCleanText\n",
    "# stopwordRemoving(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8326178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuations Removing\n",
    "import unicodedata as ud\n",
    "def punctuationsRemoving(txt):\n",
    "    ctext = ''.join(c for c in txt if not ud.category(c).startswith('P'))\n",
    "    return ctext\n",
    "# punctuationsRemoving(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede7196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISRI Stemmer\n",
    "\n",
    "st = nltk.ISRIStemmer()\n",
    "def ISRI_Stemmer(txt):\n",
    "    tkText = tokenization(txt)\n",
    "    resultStem = [st.stem(w) for w in tkText]\n",
    "    return resultStem\n",
    "# ISRI_Stemmer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55e274e",
   "metadata": {},
   "source": [
    "## GUI with tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b8ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter.messagebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5137736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/var/folders/34/f9_zspms2z3cctnc45ym9f040000gn/T/ipykernel_8465/2763260070.py\", line 34, in <lambda>\n",
      "    segmentationBtn = Button(main, text=\"Segmentation\",fg=\"Red\", command=lambda : segmentation(textbox.get()))\n",
      "  File \"/var/folders/34/f9_zspms2z3cctnc45ym9f040000gn/T/ipykernel_8465/4293236262.py\", line 7, in segmentation\n",
      "    segmentedText = punkt.tokenize(tx)\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1277, in tokenize\n",
      "    return list(self.sentences_from_text(text, realign_boundaries))\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1334, in sentences_from_text\n",
      "    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1334, in <listcomp>\n",
      "    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1324, in span_tokenize\n",
      "    for sentence in slices:\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1365, in _realign_boundaries\n",
      "    for sentence1, sentence2 in _pair_iter(slices):\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 319, in _pair_iter\n",
      "    prev = next(iterator)\n",
      "  File \"/Users/youssefeldeeb/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/punkt.py\", line 1338, in _slices_from_text\n",
      "    for match in self._lang_vars.period_context_re().finditer(text):\n",
      "TypeError: expected string or bytes-like object\n"
     ]
    }
   ],
   "source": [
    "main = Tk()\n",
    "main.title('Home')\n",
    "main.geometry(\"500x300\")\n",
    "\n",
    "#---------- Entry (textbox)-----------------\n",
    "text = StringVar()\n",
    "# text.set(\"Enter your path\")\n",
    "textbox = Entry(main, textvariable=text)\n",
    "textbox.place(x=200 ,y=50)\n",
    "\n",
    "# call function when we click on entry box\n",
    "def click(*args):\n",
    "    if textbox.get() == 'Enter Path of Dataset:- ':\n",
    "        textbox.delete(0, 'end')\n",
    "    \n",
    "#call function when we leave entry box\n",
    "def leave(*args):\n",
    "    if textbox.get() == '':\n",
    "        textbox.delete(0, 'end')\n",
    "        textbox.insert(0, 'Enter Path of Dataset:- ')\n",
    "        main.focus()\n",
    "    else:\n",
    "        main.focus()\n",
    "    \n",
    "# Add text in Entry box\n",
    "textbox.insert(0, 'Enter Path of Dataset:- ')\n",
    "textbox.pack(pady=10)\n",
    "# Use bind method\n",
    "textbox.bind(\"<Button-1>\", click)\n",
    "textbox.bind(\"<Leave>\", leave)\n",
    "\n",
    "textbox.place(x=150 ,y=15)\n",
    "#------------\n",
    "segmentationBtn = Button(main, text=\"Segmentation\",fg=\"Red\", command=lambda : segmentation(textbox.get()))\n",
    "tokenizationBtn = Button(main, text=\"Tokenization\",fg=\"Red\",)\n",
    "stopwordRemovingBtn = Button(main, text=\"Stopword Removing\",fg=\"Red\",)\n",
    "segmentationBtn.place(x=150 , y=80)\n",
    "tokenizationBtn.place(x=150 , y=110)\n",
    "stopwordRemovingBtn.place(x=150 , y=140)\n",
    "# ISRI_StemmerBtn = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd552d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02e87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1ac66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97dab5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329a567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17e338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f9026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
